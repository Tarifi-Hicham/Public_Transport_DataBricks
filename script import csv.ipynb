{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cca86ac-fab6-4a6e-91df-2fe17234d862",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year,month,dayofmonth,col,dayofweek,to_timestamp,from_unixtime,unix_timestamp,expr\n",
    "\n",
    "storage_account_name = \"tarifihicham1cs\"\n",
    "storage_account_access_key = \"Ztcio+a8JNZrV2mX9Gjl73jVSsvU1AVPVztAx0b7eYuZMwwo7u3y6Ko0A1Kjp8/MkgWXuAmN8QS0+ASt722nhA==\"\n",
    "container_name = \"tarifihichamcontainer\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
    "  storage_account_access_key)\n",
    "\n",
    "original_path = dbutils.fs.ls(f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/public_transport_data/raw\")\n",
    "\n",
    "for path in original_path:\n",
    "    filepath = dbutils.fs.ls(f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/public_transport_data/raw/\"+path.name)\n",
    "    for filename in filepath:\n",
    "        if filename.name.endswith(\".csv\"):\n",
    "            df = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/public_transport_data/raw/{path.name}/{filename.name}\")\n",
    "            # Extract year\n",
    "            df = df.withColumn(\"Year\", year(df[\"Date\"]))\n",
    "            # Extract month\n",
    "            df = df.withColumn(\"Month\", month(df[\"Date\"]))\n",
    "            # Extract day\n",
    "            df = df.withColumn(\"Day\", dayofmonth(df[\"Date\"]))\n",
    "            # Extract day of week\n",
    "            df = df.withColumn(\"DayOfWeek\", dayofweek(df[\"Date\"]))\n",
    "            # Extract duration Calculate the duration in minutes\n",
    "            df = df.withColumn(\"Duration\", expr(\"(unix_timestamp(ArrivalTime, 'HH:mm') - unix_timestamp(DepartureTime, 'HH:mm')) / 60\"))\n",
    "            \n",
    "            display(df)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aec21fe7-d33f-4bed-92d9-54cf320451e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "script import csv",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
